{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Dense, Dropout, PReLU\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from music_generator.basic.random import generate_dataset\n",
    "from music_generator.basic.signalproc import SamplingInfo\n",
    "from music_generator.musical.timing import Tempo\n",
    "from music_generator.musical.scales import GenericScale\n",
    "from music_generator.analysis.play import play_mono_as_stereo, play_array\n",
    "from music_generator.basic.signalproc import mix_at\n",
    "from music_generator.analysis import preprocessing\n",
    "\n",
    "from music_generator.musical import scales\n",
    "import numpy as np\n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_info = SamplingInfo(44100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_roots = scales.chromatic_scale('C')\n",
    "roots = [n.get_symbol() for n in all_roots.generate(0, 1)]\n",
    "roots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset_for_root(root):\n",
    "    return generate_dataset(n_measures=16,\n",
    "                            tempo=Tempo(120),\n",
    "                            scale=GenericScale(root, [0, 2, 3, 5, 7, 8, 10]),\n",
    "                            sampling_info=sampling_info)\n",
    "    \n",
    "with Pool(8) as pool:\n",
    "    datasets = pool.map(generate_dataset_for_root, roots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make one big data set and make sure data is of same size\n",
    "audio_tracks, mix = preprocessing.combine_datasets(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_tracks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# play_mono_as_stereo(mix_at(mix, -audio_tracks[2], at=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 1024 * 10\n",
    "fragment_length = 1024 * 1\n",
    "input_track = mix\n",
    "target_track = audio_tracks[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_track.shape\n",
    "# audio_tracks[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_array(input_track, sampling_info.sample_rate, range_secs=[50, 51])\n",
    "play_array(target_track, sampling_info.sample_rate, range_secs=[50, 51])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def create_training_data_set(n_samples, fragment_length, input_track, target_track):\n",
    "#     max_index = min(len(mix), len(target_track))\n",
    "#     max_start_index = max_index - fragment_length\n",
    "    \n",
    "#     # Selection range\n",
    "#     selection_ranges = np.random.randint(0, max_start_index, n_samples)\n",
    "#     selection_ranges = [{'begin': x, 'end': x + fragment_length} for x in selection_ranges]\n",
    "    \n",
    "#     x = np.array([mix[sr['begin']:sr['end']] for sr in selection_ranges])\n",
    "#     y = np.array([target_track[sr['begin']:sr['end']] for sr in selection_ranges])\n",
    "    \n",
    "#     return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = preprocessing.create_training_data_set(n_samples, \n",
    "                                              fragment_length, \n",
    "                                              input_track, \n",
    "                                              target_track)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# play_array(np.repeat(x[8], 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def x_fade_profile(batch_dim):\n",
    "    x = np.arange(batch_dim)\n",
    "    return 1 - abs(x - (batch_dim / 2)) / (batch_dim / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_predict(model, input_track):\n",
    "    dim = input_shape[0]\n",
    "    n_batches = int(len(input_track) / dim) - 1\n",
    "    pred_batches = input_track[0:n_batches*dim].reshape((-1, dim))\n",
    "    \n",
    "    pred_batches_shifted = input_track[dim//2:n_batches*dim + dim//2].reshape((-1, dim))\n",
    "    \n",
    "    xfp = x_fade_profile(dim)\n",
    "    \n",
    "    x0 = np.array([xfp * batch for batch in model.predict(pred_batches)]).reshape(-1)\n",
    "    x1 = np.array([xfp * batch for batch in model.predict(pred_batches_shifted)]).reshape(-1)\n",
    "    \n",
    "    return mix_at(x0, x1, dim//2)\n",
    "#     np.tanh()\n",
    "\n",
    "# play_array(model_predict(model, mix), do_wait_done=False)\n",
    "# play_array(model_predict(model, mix[0:5*44100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x[0].shape\n",
    "output_shape = x[1].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(Dense(1024, input_shape=input_shape))\n",
    "model.add(PReLU())\n",
    "model.add(Dense(512))\n",
    "model.add(PReLU())\n",
    "model.add(Dense(output_shape))\n",
    "model.compile(Adam(), 'mse')\n",
    "play_array(model_predict(model, mix)[0:5*44100], do_wait_done=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    model.fit(x, y, epochs=2)\n",
    "    play_array(model_predict(model, mix)[0:5*44100], do_wait_done=True)  \n",
    "    play_array(mix[0:5*44100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_array(model_predict(model, mix[0:15*44100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_array(mix[0:15*44100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io.wavfile import read\n",
    "wf = read(\"/Users/marcelraas/dev/test_data/anotherDay.wav\", mmap=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_predict_2(model, input_track):\n",
    "    dim = input_shape[0]\n",
    "    n_batches = int(len(input_track) / dim) - 1\n",
    "    pred_batches = input_track[0:n_batches*dim].reshape((-1, dim))\n",
    "    \n",
    "    return model.predict(pred_batches).reshape(-1)\n",
    "\n",
    "play_array(model_predict_2(model, wf[1][:,0]/32000), range_secs=[177, 200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_tracks_t, audio_tracks_t, mix_t = generate_dataset(n_measures=64,\n",
    "                                                         tempo=Tempo(120),\n",
    "                                                         scale=GenericScale('E', [0, 1, 4, 5, 7, 8, 10]),\n",
    "                                                         sampling_info=sampling_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_array(model_predict(model, mix_t[0:15*44100]))\n",
    "# play_array(model_predict(model, audio_tracks_t[2][0:15*44100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
