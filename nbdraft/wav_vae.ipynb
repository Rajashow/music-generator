{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datetime as dt\n",
    "\n",
    "import music_generator.analysis.preprocessing as pp\n",
    "from music_generator.analysis.play import play_array\n",
    "\n",
    "import music_generator.analysis.stft as stft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelra/Pycharmprojects/music-generator/venv/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# https://blog.keras.io/building-autoencoders-in-keras.html\n",
    "\n",
    "import keras\n",
    "\n",
    "from keras.layers import Dense, Dropout, PReLU, Input\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from keras.regularizers import l2\n",
    "from keras.models import load_model\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "\n",
    "from keras.layers import Input, Dense, Lambda\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras import metrics\n",
    "from keras.datasets import mnist, fashion_mnist\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampling_rate, data = pp.read_wave_file(\"../data/Verplichte Kots_v9.wav\", 0)\n",
    "sampling_rate, data = pp.read_wave_file(\"../data/Dream Theater - Another day-fm7ntyycGbU.wav\", 0)\n",
    "# play_array(data, sampling_rate, range_secs=[17, 31])\n",
    "# data = data[15*44100:29*44100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "stft_sample_size = 1000\n",
    "stft_stride = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12784149,)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(data).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train = stft.forward_stft(data, stft_sample_size, stft_stride)\n",
    "data = data[0:int(len(data)/stft_sample_size)*stft_sample_size]\n",
    "\n",
    "x_train = data.reshape(-1, stft_sample_size)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "# y = stft.forward_stft(data, stft_sample_size, stft_stride)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original_dim = 28 * 28\n",
    "original_dim = stft_sample_size\n",
    "intermediate_dim = 10\n",
    "latent_dim = 2\n",
    "epsilon_std = 1.0\n",
    "epochs = 1\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            (None, 1000)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 10)           10010       input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 2)            22          dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 2)            22          dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 2)            0           dense_17[0][0]                   \n",
      "                                                                 dense_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 10)           30          lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 1000)         11000       dense_19[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 21,084\n",
      "Trainable params: 21,084\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "x = Input(shape=(original_dim,))\n",
    "h = Dense(intermediate_dim, activation='relu')(x)\n",
    "z_mean = Dense(latent_dim)(h)\n",
    "z_log_var = Dense(latent_dim)(h)\n",
    "\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim), mean=0.,\n",
    "                              stddev=epsilon_std)\n",
    "    return z_mean + K.exp(z_log_var / 2) * epsilon\n",
    "\n",
    "# note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
    "z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])\n",
    "\n",
    "# we instantiate these layers separately so as to reuse them later\n",
    "decoder_h = Dense(intermediate_dim, activation='relu')\n",
    "decoder_mean = Dense(original_dim, activation='sigmoid')\n",
    "h_decoded = decoder_h(z)\n",
    "x_decoded_mean = decoder_mean(h_decoded)\n",
    "\n",
    "# instantiate VAE model\n",
    "vae = Model(x, x_decoded_mean)\n",
    "\n",
    "# Compute VAE loss\n",
    "\n",
    "def custom_loss(x, x_decoded_mean):\n",
    "    xent_loss = original_dim * metrics.mse(x, x_decoded_mean)\n",
    "    kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "    vae_loss = K.mean(xent_loss + kl_loss)\n",
    "    return vae_loss\n",
    "\n",
    "# vae.add_loss(vae_loss)\n",
    "vae.compile(optimizer='rmsprop', loss=custom_loss)\n",
    "vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "12784/12784 [==============================] - 1s 46us/step - loss: 10.0823\n",
      "Epoch 2/64\n",
      "12784/12784 [==============================] - 0s 32us/step - loss: 9.7336\n",
      "Epoch 3/64\n",
      "12784/12784 [==============================] - 0s 32us/step - loss: 9.7017\n",
      "Epoch 4/64\n",
      "12784/12784 [==============================] - 0s 31us/step - loss: 9.6910\n",
      "Epoch 5/64\n",
      "12784/12784 [==============================] - 0s 30us/step - loss: 9.6856\n",
      "Epoch 6/64\n",
      "12784/12784 [==============================] - 0s 31us/step - loss: 9.6827\n",
      "Epoch 7/64\n",
      "12784/12784 [==============================] - 0s 31us/step - loss: 9.6827\n",
      "Epoch 8/64\n",
      "12784/12784 [==============================] - 0s 32us/step - loss: 9.6816\n",
      "Epoch 9/64\n",
      "12784/12784 [==============================] - 0s 31us/step - loss: 9.6811\n",
      "Epoch 10/64\n",
      "12784/12784 [==============================] - 0s 30us/step - loss: 9.6797\n",
      "Epoch 11/64\n",
      "12784/12784 [==============================] - 0s 34us/step - loss: 9.6803\n",
      "Epoch 12/64\n",
      "12784/12784 [==============================] - 0s 32us/step - loss: 9.6802\n",
      "Epoch 13/64\n",
      "12784/12784 [==============================] - 0s 32us/step - loss: 9.6795\n",
      "Epoch 14/64\n",
      "12784/12784 [==============================] - 0s 31us/step - loss: 9.6796\n",
      "Epoch 15/64\n",
      "12784/12784 [==============================] - 0s 30us/step - loss: 9.6791\n",
      "Epoch 16/64\n",
      "12784/12784 [==============================] - 0s 32us/step - loss: 9.6789\n",
      "Epoch 17/64\n",
      "12784/12784 [==============================] - 0s 33us/step - loss: 9.6788\n",
      "Epoch 18/64\n",
      "12784/12784 [==============================] - 0s 32us/step - loss: 9.6789\n",
      "Epoch 19/64\n",
      "12784/12784 [==============================] - 0s 31us/step - loss: 9.6783\n",
      "Epoch 20/64\n",
      "12784/12784 [==============================] - 0s 32us/step - loss: 9.6786\n",
      "Epoch 21/64\n",
      "12784/12784 [==============================] - 0s 31us/step - loss: 9.6785\n",
      "Epoch 22/64\n",
      "12784/12784 [==============================] - 0s 31us/step - loss: 9.6776\n",
      "Epoch 23/64\n",
      "12784/12784 [==============================] - 0s 32us/step - loss: 9.6782\n",
      "Epoch 24/64\n",
      "12784/12784 [==============================] - 0s 32us/step - loss: 9.6779\n",
      "Epoch 25/64\n",
      "12784/12784 [==============================] - 0s 31us/step - loss: 9.6778\n",
      "Epoch 26/64\n",
      "12784/12784 [==============================] - 0s 31us/step - loss: 9.6777\n",
      "Epoch 27/64\n",
      "12784/12784 [==============================] - 0s 33us/step - loss: 9.6778\n",
      "Epoch 28/64\n",
      "12784/12784 [==============================] - 0s 31us/step - loss: 9.6779\n",
      "Epoch 29/64\n",
      "12784/12784 [==============================] - 0s 30us/step - loss: 9.6776\n",
      "Epoch 30/64\n",
      "12784/12784 [==============================] - 0s 31us/step - loss: 9.6772\n",
      "Epoch 31/64\n",
      "12784/12784 [==============================] - 0s 32us/step - loss: 9.6770\n",
      "Epoch 32/64\n",
      "12784/12784 [==============================] - 0s 32us/step - loss: 9.6773\n",
      "Epoch 33/64\n",
      "12784/12784 [==============================] - 0s 31us/step - loss: 9.6772\n",
      "Epoch 34/64\n",
      "12784/12784 [==============================] - 0s 31us/step - loss: 9.6776\n",
      "Epoch 35/64\n",
      "12784/12784 [==============================] - 0s 30us/step - loss: 9.6775\n",
      "Epoch 36/64\n",
      "12784/12784 [==============================] - 0s 35us/step - loss: 9.6773\n",
      "Epoch 37/64\n",
      "12784/12784 [==============================] - 0s 31us/step - loss: 9.6773\n",
      "Epoch 38/64\n",
      "12784/12784 [==============================] - 0s 32us/step - loss: 9.6775\n",
      "Epoch 39/64\n",
      "12784/12784 [==============================] - 0s 30us/step - loss: 9.6769\n",
      "Epoch 40/64\n",
      "12784/12784 [==============================] - 0s 31us/step - loss: 9.6768\n",
      "Epoch 41/64\n",
      "12784/12784 [==============================] - 0s 35us/step - loss: 9.6775\n",
      "Epoch 42/64\n",
      "12784/12784 [==============================] - 0s 31us/step - loss: 9.6776\n",
      "Epoch 43/64\n",
      "12784/12784 [==============================] - 0s 35us/step - loss: 9.6770\n",
      "Epoch 44/64\n",
      "12784/12784 [==============================] - 0s 30us/step - loss: 9.6769\n",
      "Epoch 45/64\n",
      "12784/12784 [==============================] - 0s 35us/step - loss: 9.6768\n",
      "Epoch 46/64\n",
      "12784/12784 [==============================] - 0s 31us/step - loss: 9.6772\n",
      "Epoch 47/64\n",
      "12784/12784 [==============================] - 0s 31us/step - loss: 9.6772\n",
      "Epoch 48/64\n",
      "12784/12784 [==============================] - 0s 31us/step - loss: 9.6770\n",
      "Epoch 49/64\n",
      "12784/12784 [==============================] - 0s 28us/step - loss: 9.6770\n",
      "Epoch 50/64\n",
      "12784/12784 [==============================] - 0s 30us/step - loss: 9.6772\n",
      "Epoch 51/64\n",
      "12784/12784 [==============================] - 0s 31us/step - loss: 9.6773\n",
      "Epoch 52/64\n",
      "12784/12784 [==============================] - 0s 30us/step - loss: 9.6767\n",
      "Epoch 53/64\n",
      "12784/12784 [==============================] - 0s 31us/step - loss: 9.6771\n",
      "Epoch 54/64\n",
      "12784/12784 [==============================] - 0s 29us/step - loss: 9.6764\n",
      "Epoch 55/64\n",
      "12784/12784 [==============================] - 0s 30us/step - loss: 9.6770\n",
      "Epoch 56/64\n",
      "12784/12784 [==============================] - 0s 30us/step - loss: 9.6770\n",
      "Epoch 57/64\n",
      "12784/12784 [==============================] - 0s 31us/step - loss: 9.6769\n",
      "Epoch 58/64\n",
      "12784/12784 [==============================] - 0s 31us/step - loss: 9.6771\n",
      "Epoch 59/64\n",
      "12784/12784 [==============================] - 0s 30us/step - loss: 9.6769\n",
      "Epoch 60/64\n",
      "12784/12784 [==============================] - 0s 30us/step - loss: 9.6769\n",
      "Epoch 61/64\n",
      "12784/12784 [==============================] - 0s 30us/step - loss: 9.6766\n",
      "Epoch 62/64\n",
      "12784/12784 [==============================] - 0s 31us/step - loss: 9.6767\n",
      "Epoch 63/64\n",
      "12784/12784 [==============================] - 0s 30us/step - loss: 9.6768\n",
      "Epoch 64/64\n",
      "12784/12784 [==============================] - 0s 30us/step - loss: 9.6770\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5434870da0>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae.fit(x_train, y=x_train,\n",
    "        # shuffle=True,\n",
    "        epochs=64,\n",
    "        batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Model(x, z_mean)\n",
    "\n",
    "# display a 2D plot of the digit classes in the latent space\n",
    "x_train_encoded = encoder.predict(x_train, batch_size=batch_size)\n",
    "\n",
    "# build a digit generator that can sample from the learned distribution\n",
    "decoder_input = Input(shape=(latent_dim,))\n",
    "_h_decoded = decoder_h(decoder_input)\n",
    "_x_decoded_mean = decoder_mean(_h_decoded)\n",
    "generator = Model(decoder_input, _x_decoded_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.graph_objs as go\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(6, 6))\n",
    "# plt.scatter(x_train_encoded[:, 0], x_train_encoded[:, 1], c=range(len(x_train_encoded)), alpha=0.01)\n",
    "trace = [go.Scatter3d(x=x_train_encoded[:, 0], \n",
    "                      y=x_train_encoded[:, 1], \n",
    "                      z=np.arange(len(x_train_encoded)),\n",
    "                      mode='markers',\n",
    "                        marker=dict(\n",
    "                            size=3,\n",
    "                            color=np.arange(len(x_train_encoded)),                # set color to an array/list of desired values\n",
    "                            colorscale='Viridis',   # choose a colorscale\n",
    "                            opacity=0.8\n",
    "                        ))]\n",
    "\n",
    "fig = go.Figure(data=trace, layout=go.Layout(height=800, width=1000))\n",
    "\n",
    "# iplot(fig)\n",
    "# plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 32\n",
    "grid_x = np.percentile(x_train_encoded[:, 0], np.linspace(0.05, 0.95, n))\n",
    "grid_y = np.percentile(x_train_encoded[:, 1], np.linspace(0.05, 0.95, n))\n",
    "# grid_x = norm.ppf(np.linspace(0.05, 0.95, n))\n",
    "# grid_y = norm.ppf(np.linspace(0.05, 0.95, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_to_reverse = []\n",
    "\n",
    "for i, yi in enumerate(grid_x):\n",
    "    for j, xi in enumerate(grid_y):\n",
    "        z_sample = np.array([[xi, yi]])\n",
    "        # print(z_sample)\n",
    "        x_decoded = generator.predict(z_sample)\n",
    "        x_decoded = scaler.inverse_transform(x_decoded)[0]\n",
    "        x_to_reverse.append(x_decoded)\n",
    "\n",
    "x_to_reverse = np.array(x_to_reverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.array(x_to_reverse).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _ = stft.backward_stft(scaler.inverse_transform(x_train), stft_stride)\n",
    "# play_array(_, range_secs=[0,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_sampled = stft.backward_stft(np.array(x_to_reverse), stft_stride)\n",
    "play_array(x_to_reverse.T.reshape(-1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
