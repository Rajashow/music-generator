{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datetime as dt\n",
    "\n",
    "import music_generator.analysis.preprocessing as pp\n",
    "from music_generator.analysis.play import play_array\n",
    "\n",
    "import music_generator.analysis.stft as stft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://blog.keras.io/building-autoencoders-in-keras.html\n",
    "\n",
    "import keras\n",
    "\n",
    "from keras.layers import Dense, Dropout, PReLU, Input\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from keras.regularizers import l2\n",
    "from keras.models import load_model\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "\n",
    "from keras.layers import Input, Dense, Lambda\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras import metrics\n",
    "from keras.datasets import mnist, fashion_mnist\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampling_rate, data = pp.read_wave_file(\"../data/Verplichte Kots_v9.wav\", 0)\n",
    "sampling_rate, data = pp.read_wave_file(\"../data/Dream Theater - Another day-fm7ntyycGbU.wav\", 0)\n",
    "# play_array(data, sampling_rate, range_secs=[17, 31])\n",
    "# data = data[15*44100:29*44100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stft_sample_size = 1000\n",
    "stft_stride = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(data).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train = stft.forward_stft(data, stft_sample_size, stft_stride)\n",
    "data = data[0:int(len(data)/stft_sample_size)*stft_sample_size]\n",
    "\n",
    "x_train = data.reshape(-1, stft_sample_size)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "# y = stft.forward_stft(data, stft_sample_size, stft_stride)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original_dim = 28 * 28\n",
    "original_dim = stft_sample_size\n",
    "intermediate_dim = 10\n",
    "latent_dim = 2\n",
    "epsilon_std = 1.0\n",
    "epochs = 1\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Input(shape=(original_dim,))\n",
    "h = Dense(intermediate_dim, activation='relu')(x)\n",
    "z_mean = Dense(latent_dim)(h)\n",
    "z_log_var = Dense(latent_dim)(h)\n",
    "\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim), mean=0.,\n",
    "                              stddev=epsilon_std)\n",
    "    return z_mean + K.exp(z_log_var / 2) * epsilon\n",
    "\n",
    "# note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
    "z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])\n",
    "\n",
    "# we instantiate these layers separately so as to reuse them later\n",
    "decoder_h = Dense(intermediate_dim, activation='relu')\n",
    "decoder_mean = Dense(original_dim, activation='sigmoid')\n",
    "h_decoded = decoder_h(z)\n",
    "x_decoded_mean = decoder_mean(h_decoded)\n",
    "\n",
    "# instantiate VAE model\n",
    "vae = Model(x, x_decoded_mean)\n",
    "\n",
    "# Compute VAE loss\n",
    "\n",
    "def custom_loss(x, x_decoded_mean):\n",
    "    xent_loss = original_dim * metrics.mse(x, x_decoded_mean)\n",
    "    kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "    vae_loss = K.mean(xent_loss + kl_loss)\n",
    "    return vae_loss\n",
    "\n",
    "# vae.add_loss(vae_loss)\n",
    "vae.compile(optimizer='rmsprop', loss=custom_loss)\n",
    "vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.fit(x_train, y=x_train,\n",
    "        # shuffle=True,\n",
    "        epochs=64,\n",
    "        batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Model(x, z_mean)\n",
    "\n",
    "# display a 2D plot of the digit classes in the latent space\n",
    "x_train_encoded = encoder.predict(x_train, batch_size=batch_size)\n",
    "\n",
    "# build a digit generator that can sample from the learned distribution\n",
    "decoder_input = Input(shape=(latent_dim,))\n",
    "_h_decoded = decoder_h(decoder_input)\n",
    "_x_decoded_mean = decoder_mean(_h_decoded)\n",
    "generator = Model(decoder_input, _x_decoded_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(6, 6))\n",
    "# plt.scatter(x_train_encoded[:, 0], x_train_encoded[:, 1], c=range(len(x_train_encoded)), alpha=0.01)\n",
    "trace = [go.Scatter3d(x=x_train_encoded[:, 0], \n",
    "                      y=x_train_encoded[:, 1], \n",
    "                      z=np.arange(len(x_train_encoded)),\n",
    "                      mode='markers',\n",
    "                        marker=dict(\n",
    "                            size=3,\n",
    "                            color=np.arange(len(x_train_encoded)),                # set color to an array/list of desired values\n",
    "                            colorscale='Viridis',   # choose a colorscale\n",
    "                            opacity=0.8\n",
    "                        ))]\n",
    "\n",
    "fig = go.Figure(data=trace, layout=go.Layout(height=800, width=1000))\n",
    "\n",
    "# iplot(fig)\n",
    "# plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 32\n",
    "grid_x = np.percentile(x_train_encoded[:, 0], np.linspace(0.05, 0.95, n))\n",
    "grid_y = np.percentile(x_train_encoded[:, 1], np.linspace(0.05, 0.95, n))\n",
    "# grid_x = norm.ppf(np.linspace(0.05, 0.95, n))\n",
    "# grid_y = norm.ppf(np.linspace(0.05, 0.95, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_to_reverse = []\n",
    "\n",
    "for i, yi in enumerate(grid_x):\n",
    "    for j, xi in enumerate(grid_y):\n",
    "        z_sample = np.array([[xi, yi]])\n",
    "        # print(z_sample)\n",
    "        x_decoded = generator.predict(z_sample)\n",
    "        x_decoded = scaler.inverse_transform(x_decoded)[0]\n",
    "        x_to_reverse.append(x_decoded)\n",
    "\n",
    "x_to_reverse = np.array(x_to_reverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.array(x_to_reverse).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _ = stft.backward_stft(scaler.inverse_transform(x_train), stft_stride)\n",
    "# play_array(_, range_secs=[0,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_sampled = stft.backward_stft(np.array(x_to_reverse), stft_stride)\n",
    "play_array(x_to_reverse.T.reshape(-1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
